{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7491c6ec-2d8d-4a86-afcd-93874665aff3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "405bd79a-d70f-44d2-b355-6167f45c95b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Deployment de Modelo de Regressão com PyTorch Usando MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d97df5b-958a-4901-bd5d-ac5b1a8a107d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substitua o catálogo e o schema que irá usar e crie\n",
    "CATALOG_NAME = \"baraldi_catalog_new\"\n",
    "SCHEMA_NAME = \"regression\"\n",
    "\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {CATALOG_NAME}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG_NAME}.{SCHEMA_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fa7aad8-848a-46b3-a795-06b7c48cd69d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# Instale as bibliotecas necessárias\n",
    "%pip install -Uqqq mlflow pytorch-lightning optuna skorch uv optuna-integration[pytorch_lightning]\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "910fbeb0-29cc-430c-8181-cf615beeb869",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importe as bibliotecas\n",
    "from typing import Tuple, Optional, Dict, List, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import Metric, Param  \n",
    "\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "250ce633-3314-4142-851b-512ae2bf9667",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configure o registry URI\n",
    "mlflow.set_registry_uri(\"databricks-uc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e733302-eb9c-40b2-89c7-e064bc2b3e0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Crie os Dados Sintéticos\n",
    "def create_regression_data(\n",
    "    n_samples: int, \n",
    "    n_features: int,\n",
    "    seed: int = 1994,\n",
    "    noise_level: float = 0.3,\n",
    "    nonlinear: bool = True\n",
    ") -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"Generates synthetic regression data with interesting correlations for MLflow and PyTorch demonstrations.\n",
    "\n",
    "    This function creates a DataFrame of continuous features and computes a target variable with nonlinear\n",
    "    relationships and interactions between features. The data is designed to be complex enough to demonstrate\n",
    "    the capabilities of deep learning, but not so complex that a reasonable model can't be learned.\n",
    "\n",
    "    Args:\n",
    "        n_samples (int): Number of samples (rows) to generate.\n",
    "        n_features (int): Number of feature columns.\n",
    "        seed (int, optional): Random seed for reproducibility. Defaults to 1994.\n",
    "        noise_level (float, optional): Level of Gaussian noise to add to the target. Defaults to 0.3.\n",
    "        nonlinear (bool, optional): Whether to add nonlinear feature transformations. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, pd.Series]:\n",
    "            - pd.DataFrame: DataFrame containing the synthetic features.\n",
    "            - pd.Series: Series containing the target labels.\n",
    "\n",
    "    Example:\n",
    "        >>> df, target = create_regression_data(n_samples=1000, n_features=10)\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    # Gere features aleatórias\n",
    "    X = rng.uniform(-5, 5, size=(n_samples, n_features))\n",
    "    \n",
    "    # Gere features com seus nomes\n",
    "    columns = [f\"feature_{i}\" for i in range(n_features)]\n",
    "    df = pd.DataFrame(X, columns=columns)\n",
    "    \n",
    "    # Gere a variável alvo com relação linear para um conjunto de features. Use features relevantes e irrelevantes\n",
    "    weights = rng.uniform(-2, 2, size=n_features//2)\n",
    "    target = np.dot(X[:, :n_features//2], weights)\n",
    "    \n",
    "    # Adicione transformações não-lineares caso necessário\n",
    "    if nonlinear:\n",
    "        # Adicione termo ao quadrado para primeira feature\n",
    "        target += 0.5 * X[:, 0]**2\n",
    "        \n",
    "        # Adicione interação entre a segunda e a terceira features\n",
    "        if n_features >= 3:\n",
    "            target += 1.5 * X[:, 1] * X[:, 2]\n",
    "        \n",
    "        # Adicione transformação com seno para a quarta\n",
    "        if n_features >= 4:\n",
    "            target += 2 * np.sin(X[:, 3])\n",
    "        \n",
    "        # Adicione exponencial para a quinta\n",
    "        if n_features >= 5:\n",
    "            target += 0.1 * np.exp(X[:, 4] / 2)\n",
    "            \n",
    "        # Adicione efeito de limiar para a sexta\n",
    "        if n_features >= 6:\n",
    "            target += 3 * (X[:, 5] > 1.5).astype(float)\n",
    "    \n",
    "    # Adicione ruído de gaussiana\n",
    "    noise = rng.normal(0, noise_level * target.std(), size=n_samples)\n",
    "    target += noise\n",
    "    \n",
    "    # Adicione mais features ao DataFrame\n",
    "    \n",
    "    # Adicione uma feature correlata (mas não usada no alvo)\n",
    "    if n_features >= 7:\n",
    "        df['feature_correlated'] = df['feature_0'] * 0.8 + rng.normal(0, 0.2, size=n_samples)\n",
    "    \n",
    "    # Adicione uma feature cíclica\n",
    "    df['feature_cyclical'] = np.sin(np.linspace(0, 4*np.pi, n_samples))\n",
    "    \n",
    "    # Adicione uma feature com outliers\n",
    "    df['feature_with_outliers'] = rng.normal(0, 1, size=n_samples)\n",
    "    \n",
    "    # Adicione outliers\n",
    "    outlier_idx = rng.choice(n_samples, size=n_samples//100, replace=False)\n",
    "    df.loc[outlier_idx, 'feature_with_outliers'] = rng.uniform(10, 15, size=len(outlier_idx))\n",
    "    \n",
    "    return df, pd.Series(target, name='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b07875f-f1f6-419b-bcb4-83a7f4e8d606",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Realize a análise exploratória\n",
    "def plot_feature_distributions(X: pd.DataFrame, y: pd.Series, n_cols: int = 3) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Creates a grid of histograms for each feature in the dataset.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): DataFrame containing features.\n",
    "        y (pd.Series): Series containing the target variable.\n",
    "        n_cols (int): Number of columns in the grid layout.\n",
    "\n",
    "    Returns:\n",
    "        plt.Figure: The matplotlib Figure object containing the distribution plots.\n",
    "    \"\"\"\n",
    "    features = X.columns\n",
    "    n_features = len(features)\n",
    "    n_rows = (n_features + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4 * n_rows))\n",
    "    axes = axes.flatten() if n_rows * n_cols > 1 else [axes]\n",
    "    \n",
    "    for i, feature in enumerate(features):\n",
    "        if i < len(axes):\n",
    "            ax = axes[i]\n",
    "            sns.histplot(X[feature], ax=ax, kde=True, color='skyblue')\n",
    "            ax.set_title(f'Distribution of {feature}')\n",
    "    \n",
    "    # Esconda qualquer plot não usado\n",
    "    for i in range(n_features, len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.suptitle('Feature Distributions', y=1.02, fontsize=16)\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "def plot_correlation_heatmap(X: pd.DataFrame, y: pd.Series) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Creates a correlation heatmap of all features and the target variable.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): DataFrame containing features.\n",
    "        y (pd.Series): Series containing the target variable.\n",
    "\n",
    "    Returns:\n",
    "        plt.Figure: The matplotlib Figure object containing the heatmap.\n",
    "    \"\"\"\n",
    "    # Combine features e target em um DataFrame\n",
    "    data = X.copy()\n",
    "    data['target'] = y\n",
    "    \n",
    "    # Calcule a matriz de correlação\n",
    "    corr_matrix = data.corr()\n",
    "    \n",
    "    # Configure a figura\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    # Desenhe o heatmap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap=cmap,\n",
    "                center=0, square=True, linewidths=0.5, ax=ax)\n",
    "    \n",
    "    ax.set_title('Feature Correlation Heatmap', fontsize=16)\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "def plot_feature_target_relationships(X: pd.DataFrame, y: pd.Series, n_cols: int = 3) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Creates a grid of scatter plots showing the relationship between each feature and the target.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): DataFrame containing features.\n",
    "        y (pd.Series): Series containing the target variable.\n",
    "        n_cols (int): Number of columns in the grid layout.\n",
    "\n",
    "    Returns:\n",
    "        plt.Figure: The matplotlib Figure object containing the relationship plots.\n",
    "    \"\"\"\n",
    "    features = X.columns\n",
    "    n_features = len(features)\n",
    "    n_rows = (n_features + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4 * n_rows))\n",
    "    axes = axes.flatten() if n_rows * n_cols > 1 else [axes]\n",
    "    \n",
    "    for i, feature in enumerate(features):\n",
    "        if i < len(axes):\n",
    "            ax = axes[i]\n",
    "            # Plote com a regressão\n",
    "            sns.regplot(x=X[feature], y=y, ax=ax, \n",
    "                       scatter_kws={'alpha': 0.5, 'color': 'blue'}, \n",
    "                       line_kws={'color': 'red'})\n",
    "            ax.set_title(f'{feature} vs Target')\n",
    "    \n",
    "    for i in range(n_features, len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.suptitle('Feature vs Target Relationships', y=1.02, fontsize=16)\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "def plot_pairwise_relationships(X: pd.DataFrame, y: pd.Series, features: list[str]) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Creates a pairplot showing relationships between selected features and the target.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): DataFrame containing features.\n",
    "        y (pd.Series): Series containing the target variable.\n",
    "        features (List[str]): List of feature names to include in the plot.\n",
    "\n",
    "    Returns:\n",
    "        plt.Figure: The matplotlib Figure object containing the pairplot.\n",
    "    \"\"\"\n",
    "    # Garanta que features existam no DataFrame\n",
    "    valid_features = [f for f in features if f in X.columns]\n",
    "    \n",
    "    if not valid_features:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.text(0.5, 0.5, \"No valid features provided\", ha='center', va='center')\n",
    "        return fig\n",
    "    \n",
    "    # Combine features selecionadas e a variável alvo\n",
    "    data = X[valid_features].copy()\n",
    "    data['target'] = y\n",
    "    \n",
    "    # Crie um plot\n",
    "    pairgrid = sns.pairplot(data, diag_kind=\"kde\", \n",
    "                          plot_kws={\"alpha\": 0.6, \"s\": 50},\n",
    "                          corner=True)\n",
    "    \n",
    "    pairgrid.fig.suptitle(\"Pairwise Feature Relationships\", y=1.02, fontsize=16)\n",
    "    plt.close(pairgrid.fig)\n",
    "    return pairgrid.fig\n",
    "\n",
    "def plot_outliers(X: pd.DataFrame, n_cols: int = 3) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Creates a grid of box plots to detect outliers in each feature.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): DataFrame containing features.\n",
    "        n_cols (int): Number of columns in the grid layout.\n",
    "\n",
    "    Returns:\n",
    "        plt.Figure: The matplotlib Figure object containing the outlier plots.\n",
    "    \"\"\"\n",
    "    features = X.columns\n",
    "    n_features = len(features)\n",
    "    n_rows = (n_features + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4 * n_rows))\n",
    "    axes = axes.flatten() if n_rows * n_cols > 1 else [axes]\n",
    "    \n",
    "    for i, feature in enumerate(features):\n",
    "        if i < len(axes):\n",
    "            ax = axes[i]\n",
    "            # Use box plot para verificar outliers\n",
    "            sns.boxplot(x=X[feature], ax=ax, color='skyblue')\n",
    "            ax.set_title(f'Outlier Detection for {feature}')\n",
    "            ax.set_xlabel(feature)\n",
    "    \n",
    "    # Esconda plots não usados\n",
    "    for i in range(n_features, len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.suptitle('Outlier Detection for Features', y=1.02, fontsize=16)\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "def plot_residuals(y_true: pd.Series, y_pred: np.ndarray) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Creates a residual plot to analyze model prediction errors.\n",
    "    \n",
    "    Args:\n",
    "        y_true (pd.Series): True target values.\n",
    "        y_pred (np.ndarray): Predicted target values.\n",
    "        \n",
    "    Returns:\n",
    "        plt.Figure: The matplotlib Figure object containing the residual plot.\n",
    "    \"\"\"\n",
    "    residuals = y_true - y_pred\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Plote valores preditos vs residuais\n",
    "    ax.scatter(y_pred, residuals, alpha=0.5)\n",
    "    ax.axhline(y=0, color='r', linestyle='-')\n",
    "    \n",
    "    ax.set_xlabel('Predicted Values')\n",
    "    ax.set_ylabel('Residuals')\n",
    "    ax.set_title('Residual Plot')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff1c21fb-fd67-408f-b7af-217cf9e66465",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Crie a rede neural para regressão\n",
    "class RegressionNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A flexible feedforward neural network for regression tasks.\n",
    "    \n",
    "    Attributes:\n",
    "        input_dim (int): Number of input features.\n",
    "        hidden_dims (List[int]): List of hidden layer dimensions.\n",
    "        dropout_rate (float): Dropout probability for regularization.\n",
    "        use_layer_norm (bool): Whether to use layer normalization.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dims: List[int] = [64, 32],\n",
    "        dropout_rate: float = 0.1,\n",
    "        use_layer_norm: bool = True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the neural network.\n",
    "        \n",
    "        Args:\n",
    "            input_dim (int): Number of input features.\n",
    "            hidden_dims (List[int]): List of hidden layer dimensions.\n",
    "            dropout_rate (float): Dropout probability for regularization.\n",
    "            use_layer_norm (bool): Whether to use layer normalization.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.use_layer_norm = use_layer_norm\n",
    "        \n",
    "        # Construa as camadas dinamicamente\n",
    "        layers = []\n",
    "        \n",
    "        # Camada de entrada\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        # Camadas escondidas\n",
    "        for dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, dim))\n",
    "            \n",
    "            if use_layer_norm:\n",
    "                layers.append(nn.LayerNorm(dim))\n",
    "                \n",
    "            layers.append(nn.ReLU())\n",
    "            \n",
    "            if dropout_rate > 0:\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "                \n",
    "            prev_dim = dim\n",
    "        \n",
    "        # Camada de saída\n",
    "        layers.append(nn.Linear(prev_dim, 1))\n",
    "        \n",
    "        # Combine todas as camadas\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the network.\"\"\"\n",
    "        return self.model(x).squeeze()\n",
    "    \n",
    "    def get_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return model parameters as a dictionary for MLflow logging.\"\"\"\n",
    "        return {\n",
    "            \"input_dim\": self.input_dim,\n",
    "            \"hidden_dims\": self.hidden_dims,\n",
    "            \"dropout_rate\": self.dropout_rate,\n",
    "            \"use_layer_norm\": self.use_layer_norm\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a68c36a-4934-41c6-b9fc-f6ef164af75e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Crie o wrapper para a rede neural\n",
    "class RegressionLightningModule(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    PyTorch Lightning module for regression tasks.\n",
    "    \n",
    "    This class wraps the RegressionNN model and adds training, validation,\n",
    "    and testing logic using the PyTorch Lightning framework.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dims: List[int] = [64, 32],\n",
    "        dropout_rate: float = 0.1,\n",
    "        use_layer_norm: bool = True,\n",
    "        learning_rate: float = 1e-3,\n",
    "        weight_decay: float = 1e-5\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the Lightning module.\n",
    "        \n",
    "        Args:\n",
    "            input_dim (int): Number of input features.\n",
    "            hidden_dims (List[int]): List of hidden layer dimensions.\n",
    "            dropout_rate (float): Dropout probability for regularization.\n",
    "            use_layer_norm (bool): Whether to use layer normalization.\n",
    "            learning_rate (float): Learning rate for the optimizer.\n",
    "            weight_decay (float): Weight decay for L2 regularization.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Salve os hiperparâmetros\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Crie o modelo\n",
    "        self.model = RegressionNN(\n",
    "            input_dim=input_dim,\n",
    "            hidden_dims=hidden_dims,\n",
    "            dropout_rate=dropout_rate,\n",
    "            use_layer_norm=use_layer_norm\n",
    "        )\n",
    "        \n",
    "        # Função de perda\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the network.\"\"\"\n",
    "        return self.model(x)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure the optimizer for training.\"\"\"\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.learning_rate,\n",
    "            weight_decay=self.hparams.weight_decay\n",
    "        )\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"Perform a training step.\"\"\"\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = self.loss_fn(y_pred, y)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"Perform a validation step.\"\"\"\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = self.loss_fn(y_pred, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        \n",
    "        # Calcule métricas\n",
    "        rmse = torch.sqrt(loss)\n",
    "        mae = torch.mean(torch.abs(y_pred - y))\n",
    "        \n",
    "        self.log('val_rmse', rmse, prog_bar=True)\n",
    "        self.log('val_mae', mae, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \"\"\"Perform a test step.\"\"\"\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = self.loss_fn(y_pred, y)\n",
    "        \n",
    "        # Calcule métricas\n",
    "        rmse = torch.sqrt(loss)\n",
    "        mae = torch.mean(torch.abs(y_pred - y))\n",
    "        \n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_rmse', rmse)\n",
    "        self.log('test_mae', mae)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def get_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return model parameters as a dictionary for MLflow logging.\"\"\"\n",
    "        return {\n",
    "            \"input_dim\": self.hparams.input_dim,\n",
    "            \"hidden_dims\": self.hparams.hidden_dims,\n",
    "            \"dropout_rate\": self.hparams.dropout_rate,\n",
    "            \"use_layer_norm\": self.hparams.use_layer_norm,\n",
    "            \"learning_rate\": self.hparams.learning_rate,\n",
    "            \"weight_decay\": self.hparams.weight_decay\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00757850-164b-4030-bb69-79c959276280",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Crie o carregamento de dados\n",
    "def prepare_dataloader(\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, batch_size: int = 32\n",
    "):\n",
    "    \"\"\"\n",
    "    Create PyTorch DataLoaders for training, validation, and testing.\n",
    "    \n",
    "    Args:\n",
    "        X_train, y_train: Training data and labels.\n",
    "        X_val, y_val: Validation data and labels.\n",
    "        X_test, y_test: Test data and labels.\n",
    "        batch_size (int): Batch size for the DataLoaders.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (train_loader, val_loader, test_loader, scaler)\n",
    "    \"\"\"\n",
    "    # Inicialize o scaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Use fit e transform nos dados de treinamento\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Converta para tensores do PyTorch\n",
    "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "    \n",
    "    X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "    \n",
    "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "    \n",
    "    # Crie TensorDatasets\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    \n",
    "    # Crie DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "228a7b40-51bb-41c5-9463-9e4bcf0e9fd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /Workspace/Users/daniel.baraldi@databricks.com/LaboratorioDatabricks/checkpoints exists and is not empty.\n\n  | Name    | Type         | Params | Mode \n-------------------------------------------------\n0 | model   | RegressionNN | 3.2 K  | train\n1 | loss_fn | MSELoss      | 0      | train\n-------------------------------------------------\n3.2 K     Trainable params\n0         Non-trainable params\n3.2 K     Total params\n0.013     Total estimated model params size (MB)\n12        Modules in train mode\n0         Modules in eval mode\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6157f4b591204ad496e9ccd599429bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4709a0bfee443ea9e5f53d098e28ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4e3fa2be124c35942d1d906a0c77ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5790aaf7fa944afca3fdc012f5a67216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c42674aea44b908e2fb29b1c5f20ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406302a702544e2eadc811121076b136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272aa44cfdac4971a0f97b67c1c19875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6f3046a3894f6aa71353f2544be023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0d5e7fea824adc88243f719b834aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1150669f635d4b71817b66f387bb1be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69dd1abd239405582865d743d4af5ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84629060395649e4a2fcad8e4e0b955d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd74f91bf2514301b1dfcb97955e52f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c629a8d4e7db41c7aea1e4c2912b99f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38824d549074e228456fa08e024b1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552860f9cf534631ad287206f5a83623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab54392248bb499dafd0c43231068452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd8c4a9421646bc8bb09170d4a88894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81316a418394cb2a431228bc521eeea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2666c506c8542abb52c553171c0d883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd7c13a740647f58a4d193246faecc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e13e0b131d4a9b834d9162fed5aefc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b25deb067c4174be44be4e80225687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aedb55ecfa940d883a4d44554925d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "054452f93be24f0a9823efabcb2dacf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e9365ba73949d3b729167fdfecaf8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3745ef14a1b4301a475d66eb104cade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede754c123674d97875ad71b79773e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380fdd47da7d4fce879ee8346d287196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ccf8a1487e40e780b9396811118304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7b70b072034e6fb85773288e6305d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b58fd992c1c41afbd9973ab51b265ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3fe167219a41738763f31703dc0915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef785aa9ea964a4086c8119ff6597a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc6325ab3e845b58e5006ca2aeb1b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ea884a565a4b67aa9666d3326f8838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed1673aba65428db473111487c586ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c7efa445c04300b98627e0561da9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1657c3ebf93a4d39a7f14f392330f83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3c0b52b99046239307f4e296491577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f89efcaa904b9fab7fdae30627c7e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ddfe723c5344290b83a6d4eb8dc2ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c036ff365547fca4e7214b8e70835c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea9bd225723246f5ae913368a9824d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56495eae3af64461ac9f788034cda7d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6253d09afc410b8acc68ad8462f07c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa26b333db2147f39e3ba8cb4ac22ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d1825a09094b7b9a2f7047c76b1df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a5b2d72b4f41b59d2b4a89665829a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454c21759071497c8ec847d6d1a505fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec519d2e1c14340b878441762c135fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b71915a0f274648a465ac53abdc6fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7335046d81734be18ae3f4f1d096df16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a75431b80648478cf8c17cd3e66aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a746b268db944f9fb66ea34bcc3d1499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61fc06b8156e45afb59b75a280ec9eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f226ca37962492dbbc9351cd1421fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6797430bab64265b095eaac5514064a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9627e3d3c26142ce836141423b7f3781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8fa8baf22ab4c0eacff1e265ee1f4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e367ce2c0824755bdd433b4a7a95245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a466700386b64c35b0b2fbf7594df1c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71ce7ca84ef4f75b52c600f8c02e805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a966ce1f2c2c482b9bc4bfaebdb061e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f697b3955f64663b4cecffa7cb48218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "880d9046e7264ffbb47e3bf481d897a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f05263f6984b3688d8ad2ac308a550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b0c81b22e44e31b5fb5b6ae3c803fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b552aacae5dc441bb3c2aa92a1b3647d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af92d42013a41c682eee09c231a092c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6455c30b5784612928c22068341d350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ce6ebc13e647b2aeb7439b04e8c380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3512ee62e3d416c8f14ef0f09ffed86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c8e969f1f643e6883fbc9fa4a89593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138bf0cd0585478aa57d9f0a7510c6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b951fb7845ae4ba19964cb880d00f4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16fb8de9b894787b4195664e8a243cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f589a7195cb14567a940c50d36a7c61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e6dda5b7b44d87a439796f35e817ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b16084bc834b1d80fbddad0e850849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a969c9cf5dce49eeae5c620edd60a467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beafc35b869d46fc95203f36bda65fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c663c05d00e4ef5b7ff715e9853b16e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c5062b66c34472b6a08df134d1e3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab4c256340d49c9b1b8d75971eb7160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c59670b4e554c84ae9a5e7ebf2afaaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fbdcd4bbfb84f22acd6cd81f4135ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb5940a91ef4de289765995dde33110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5322a1f9c5fa4f63a6ba37da2f134c38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66078f8f8a7b44c18a1176abbfd81726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45315627bf141c2b9c78b462b4e5418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654df45253d1402fa82f1019c94cd38c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0539cf44187a462390c14433816cb9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d612a67467e434da5d8270016800dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feae22d424484d79b840567843bcd04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeedfae3ee2242fd9a67ac2b084f39ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     38.2243766784668      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mae          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     4.969927787780762     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_rmse         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     6.154206275939941     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1m       Test metric       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      DataLoader 0       \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001B[36m \u001B[0m\u001B[36m        test_loss        \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m    38.2243766784668     \u001B[0m\u001B[35m \u001B[0m│\n",
       "│\u001B[36m \u001B[0m\u001B[36m        test_mae         \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m    4.969927787780762    \u001B[0m\u001B[35m \u001B[0m│\n",
       "│\u001B[36m \u001B[0m\u001B[36m        test_rmse        \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m    6.154206275939941    \u001B[0m\u001B[35m \u001B[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crie o dataset de regressão\n",
    "n_samples = 1000\n",
    "n_features = 10\n",
    "X, y = create_regression_data(n_samples=n_samples, n_features=n_features, nonlinear=True)\n",
    "\n",
    "# Crie os gráficos de análise\n",
    "dist_plot = plot_feature_distributions(X, y)\n",
    "corr_plot = plot_correlation_heatmap(X, y)\n",
    "scatter_plot = plot_feature_target_relationships(X, y)\n",
    "corr_with_target = X.corrwith(y).abs().sort_values(ascending=False)\n",
    "top_features = corr_with_target.head(4).index.tolist()\n",
    "pairwise_plot = plot_pairwise_relationships(X, y, top_features)\n",
    "outlier_plot = plot_outliers(X)\n",
    "\n",
    "# Divida entre treino, teste e validação\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Prepare os DataLoaders\n",
    "batch_size = 32\n",
    "train_loader, val_loader, test_loader, scaler = prepare_dataloader(\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "# Defina parâmetros do modelo\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dims = [64, 32]\n",
    "dropout_rate = 0.1\n",
    "use_layer_norm = True\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-5\n",
    "\n",
    "# Crie o wrapper PyTorch Lightning\n",
    "model = RegressionLightningModule(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dims=hidden_dims,\n",
    "    dropout_rate=dropout_rate,\n",
    "    use_layer_norm=use_layer_norm,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "\n",
    "# Defina a parada e os callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='./checkpoints',\n",
    "    filename='pytorch-regression-{epoch:02d}-{val_loss:.4f}',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Defina o trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    callbacks=[early_stopping, checkpoint_callback],\n",
    "    enable_progress_bar=True,\n",
    "    log_every_n_steps=5\n",
    ")\n",
    "\n",
    "# Treine o modelo\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "# Teste o modelo\n",
    "test_results = trainer.test(model, test_loader)\n",
    "\n",
    "# Faça predições no teste\n",
    "model.eval()\n",
    "test_preds = []\n",
    "true_values = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x, y = batch\n",
    "        y_pred = model(x)\n",
    "        test_preds.extend(y_pred.numpy())\n",
    "        true_values.extend(y.numpy())\n",
    "\n",
    "test_preds = np.array(test_preds)\n",
    "true_values = np.array(true_values)\n",
    "\n",
    "# Calcule métricas\n",
    "rmse = np.sqrt(mean_squared_error(true_values, test_preds))\n",
    "mae = mean_absolute_error(true_values, test_preds)\n",
    "r2 = r2_score(true_values, test_preds)\n",
    "\n",
    "# Crie o gráfico residual\n",
    "residual_plot = plot_residuals(pd.Series(true_values), test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90176a73-23fa-4fa0-a74f-17e95362aab6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n2025/09/24 17:22:39 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n\uD83D\uDD17 View Logged Model at: https://e2-demo-field-eng.cloud.databricks.com/ml/experiments/2964497923484677/models/m-9b952b2f8a8d43b48dff347da285bf6a?o=1444828305810485\nRegistered model 'baraldi_catalog.regression.pytorch_regression_model' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86458b19c5ea47e1bb7613aec8afc8bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD17 Created version '3' of model 'baraldi_catalog.regression.pytorch_regression_model': https://e2-demo-field-eng.cloud.databricks.com/explore/data/models/baraldi_catalog/regression/pytorch_regression_model/version/3?o=1444828305810485\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logged: models:/m-9b952b2f8a8d43b48dff347da285bf6a\nTest RMSE: 6.1826\nTest MAE: 4.9699\nTest R²: 0.8468\n"
     ]
    }
   ],
   "source": [
    "# Registre o modelo e resultados de treino com MLflow\n",
    "with mlflow.start_run() as run:\n",
    "    # Crie o client do MLflow client para registro em batch\n",
    "    mlflow_client = MlflowClient()\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    # Extraia métricas\n",
    "    final_train_loss = trainer.callback_metrics.get(\"train_loss\").item() if \"train_loss\" in trainer.callback_metrics else None\n",
    "    final_val_loss = trainer.callback_metrics.get(\"val_loss\").item() if \"val_loss\" in trainer.callback_metrics else None\n",
    "    \n",
    "    # Extraia parametros para registro\n",
    "    model_params = model.get_params()\n",
    "     \n",
    "    # Crie uma lista para armazenar todas as métricas para registro em batch\n",
    "    all_metrics = []\n",
    "    \n",
    "    # Adicione cada métrica à lista\n",
    "    if final_train_loss is not None:\n",
    "        all_metrics.append(Metric(key=\"train_loss\", value=final_train_loss, timestamp=0, step=0))\n",
    "    if final_val_loss is not None:\n",
    "        all_metrics.append(Metric(key=\"val_loss\", value=final_val_loss, timestamp=0, step=0))\n",
    "    \n",
    "    # Adicione métricas de teste\n",
    "    all_metrics.append(Metric(key=\"test_rmse\", value=rmse, timestamp=0, step=0))\n",
    "    all_metrics.append(Metric(key=\"test_mae\", value=mae, timestamp=0, step=0))\n",
    "    all_metrics.append(Metric(key=\"test_r2\", value=r2, timestamp=0, step=0))\n",
    "    \n",
    "    # Colete todos os parâmetros para registrar\n",
    "    # Note: The code uses log_params for model_params since there could be many parameters,\n",
    "    # but converts the individual param calls to batch\n",
    "    from mlflow.entities import Param\n",
    "    all_params = [\n",
    "        Param(key=\"batch_size\", value=str(batch_size)),\n",
    "        Param(key=\"early_stopping_patience\", value=str(early_stopping.patience)),\n",
    "        Param(key=\"max_epochs\", value=str(trainer.max_epochs)),\n",
    "        Param(key=\"actual_epochs\", value=str(trainer.current_epoch))\n",
    "    ]\n",
    "    \n",
    "    # Gere uma assinatura do modelo usando o infer signature no MLflow\n",
    "    input_example = X_train.iloc[[0]].values.astype(np.float32)\n",
    "    input_example_scaled = scaler.transform(input_example).astype(np.float32)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tensor_input = torch.tensor(input_example_scaled, dtype=torch.float32)\n",
    "        signature_preds = model(tensor_input)\n",
    "    \n",
    "    signature = infer_signature(input_example, signature_preds.numpy().reshape(-1).astype(np.float32))\n",
    "    \n",
    "    # Registre os parâmetros do modelo primeiro\n",
    "    mlflow.log_params(model_params)\n",
    "    \n",
    "    # Registre todas as métricas e parâmetros restantes\n",
    "    mlflow_client.log_batch(\n",
    "        run_id=run_id,\n",
    "        metrics=all_metrics,\n",
    "        params=all_params\n",
    "    )\n",
    "    \n",
    "    # Registre o modelo para o MLflow e para o Unity Catalog\n",
    "    model_info = mlflow.pytorch.log_model(\n",
    "        model,\n",
    "        artifact_path=\"model\",\n",
    "        input_example=input_example,\n",
    "        signature=signature,\n",
    "        registered_model_name=\"baraldi_catalog.regression.pytorch_regression_model\",\n",
    "    )\n",
    "    \n",
    "    # Registre os gráficos\n",
    "    mlflow.log_figure(dist_plot, \"feature_distributions.png\")\n",
    "    mlflow.log_figure(corr_plot, \"correlation_heatmap.png\")\n",
    "    mlflow.log_figure(scatter_plot, \"feature_target_relationships.png\")\n",
    "    mlflow.log_figure(pairwise_plot, \"pairwise_relationships.png\")\n",
    "    mlflow.log_figure(outlier_plot, \"outlier_detection.png\")\n",
    "    mlflow.log_figure(residual_plot, \"residual_plot.png\")\n",
    "    \n",
    "    # Execute a avaliação do MLflow para gerar métricas adicionais\n",
    "    evaluation_data = X_test.copy()\n",
    "    evaluation_data[\"label\"] = y_test\n",
    "    \n",
    "    # Pule o mlflow.evaluate agora para evitar problemas de tipagem\n",
    "    print(f\"Model logged: {model_info.model_uri}\")\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n",
    "    print(f\"Test MAE: {mae:.4f}\")\n",
    "    print(f\"Test R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91d1ba3b-ac26-4b0e-a1e6-9945450e6528",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 17:23:07,542] A new study created in memory with name: no-name-9761ab9f-4cef-4e11-9c3f-d30c12db5e74\n\uD83D\uDCA1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name    | Type         | Params | Mode \n-------------------------------------------------\n0 | model   | RegressionNN | 13.2 K | train\n1 | loss_fn | MSELoss      | 0      | train\n-------------------------------------------------\n13.2 K    Trainable params\n0         Non-trainable params\n13.2 K    Total params\n0.053     Total estimated model params size (MB)\n12        Modules in train mode\n0         Modules in eval mode\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/optuna/trial/_trial.py:501: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n  warnings.warn(\nWARNING:root:No handler for 81ea884a565a4b67aa9666d3326f8838\nWARNING:root:No handler for 9ed1673aba65428db473111487c586ef\nWARNING:root:No handler for b7c7efa445c04300b98627e0561da9d3\nWARNING:root:No handler for 1657c3ebf93a4d39a7f14f392330f83e\nWARNING:root:No handler for 9b3c0b52b99046239307f4e296491577\nWARNING:root:No handler for 48f89efcaa904b9fab7fdae30627c7e1\nWARNING:root:No handler for 2ddfe723c5344290b83a6d4eb8dc2ca8\nWARNING:root:No handler for 41c036ff365547fca4e7214b8e70835c\nWARNING:root:No handler for ea9bd225723246f5ae913368a9824d85\nWARNING:root:No handler for 56495eae3af64461ac9f788034cda7d3\nWARNING:root:No handler for 2f6253d09afc410b8acc68ad8462f07c\nWARNING:root:No handler for aa26b333db2147f39e3ba8cb4ac22ad9\nWARNING:root:No handler for d4d1825a09094b7b9a2f7047c76b1df4\nWARNING:root:No handler for 88a5b2d72b4f41b59d2b4a89665829a6\nWARNING:root:No handler for 454c21759071497c8ec847d6d1a505fc\nWARNING:root:No handler for dec519d2e1c14340b878441762c135fd\nWARNING:root:No handler for 9b71915a0f274648a465ac53abdc6fed\nWARNING:root:No handler for 7335046d81734be18ae3f4f1d096df16\nWARNING:root:No handler for 31a75431b80648478cf8c17cd3e66aa8\nWARNING:root:No handler for a746b268db944f9fb66ea34bcc3d1499\nWARNING:root:No handler for 61fc06b8156e45afb59b75a280ec9eb0\nWARNING:root:No handler for 8f226ca37962492dbbc9351cd1421fa7\nWARNING:root:No handler for c6797430bab64265b095eaac5514064a\nWARNING:root:No handler for 9627e3d3c26142ce836141423b7f3781\nWARNING:root:No handler for b8fa8baf22ab4c0eacff1e265ee1f4ed\nWARNING:root:No handler for 7e367ce2c0824755bdd433b4a7a95245\nWARNING:root:No handler for a466700386b64c35b0b2fbf7594df1c7\nWARNING:root:No handler for a71ce7ca84ef4f75b52c600f8c02e805\nWARNING:root:No handler for a966ce1f2c2c482b9bc4bfaebdb061e3\nWARNING:root:No handler for 8f697b3955f64663b4cecffa7cb48218\nWARNING:root:No handler for 880d9046e7264ffbb47e3bf481d897a2\nWARNING:root:No handler for 25f05263f6984b3688d8ad2ac308a550\nWARNING:root:No handler for 18b0c81b22e44e31b5fb5b6ae3c803fe\nWARNING:root:No handler for b552aacae5dc441bb3c2aa92a1b3647d\nWARNING:root:No handler for 9af92d42013a41c682eee09c231a092c\nWARNING:root:No handler for f6455c30b5784612928c22068341d350\nWARNING:root:No handler for 57ce6ebc13e647b2aeb7439b04e8c380\nWARNING:root:No handler for d3512ee62e3d416c8f14ef0f09ffed86\nWARNING:root:No handler for e5c8e969f1f643e6883fbc9fa4a89593\nWARNING:root:No handler for 138bf0cd0585478aa57d9f0a7510c6d5\nWARNING:root:No handler for b951fb7845ae4ba19964cb880d00f4c2\nWARNING:root:No handler for c16fb8de9b894787b4195664e8a243cd\nWARNING:root:No handler for f589a7195cb14567a940c50d36a7c61f\nWARNING:root:No handler for 08e6dda5b7b44d87a439796f35e817ab\nWARNING:root:No handler for 75b16084bc834b1d80fbddad0e850849\nWARNING:root:No handler for a969c9cf5dce49eeae5c620edd60a467\nWARNING:root:No handler for beafc35b869d46fc95203f36bda65fce\nWARNING:root:No handler for 9c663c05d00e4ef5b7ff715e9853b16e\nWARNING:root:No handler for 86c5062b66c34472b6a08df134d1e3db\nWARNING:root:No handler for aab4c256340d49c9b1b8d75971eb7160\nWARNING:root:No handler for 3c59670b4e554c84ae9a5e7ebf2afaaf\nWARNING:root:No handler for 5fbdcd4bbfb84f22acd6cd81f4135ac3\nWARNING:root:No handler for 2eb5940a91ef4de289765995dde33110\nWARNING:root:No handler for 5322a1f9c5fa4f63a6ba37da2f134c38\nWARNING:root:No handler for 66078f8f8a7b44c18a1176abbfd81726\nWARNING:root:No handler for e45315627bf141c2b9c78b462b4e5418\nWARNING:root:No handler for 654df45253d1402fa82f1019c94cd38c\nWARNING:root:No handler for 0539cf44187a462390c14433816cb9d8\nWARNING:root:No handler for 5d612a67467e434da5d8270016800dc1\nWARNING:root:No handler for feae22d424484d79b840567843bcd04a\n[I 2025-09-24 17:23:40,300] Trial 0 finished with value: 29.293935775756836 and parameters: {'n_layers': 2, 'hidden_dim_0': 127, 'hidden_dim_1': 85, 'dropout_rate': 0.21705774597504107, 'learning_rate': 0.002568098342668749, 'weight_decay': 3.975997430876517e-06, 'use_layer_norm': True}. Best is trial 0 with value: 29.293935775756836.\n\uD83D\uDCA1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name    | Type         | Params | Mode \n-------------------------------------------------\n0 | model   | RegressionNN | 11.3 K | train\n1 | loss_fn | MSELoss      | 0      | train\n-------------------------------------------------\n11.3 K    Trainable params\n0         Non-trainable params\n11.3 K    Total params\n0.045     Total estimated model params size (MB)\n16        Modules in train mode\n0         Modules in eval mode\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/optuna/trial/_trial.py:501: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n  warnings.warn(\n[I 2025-09-24 17:24:14,206] Trial 1 finished with value: 43.45340347290039 and parameters: {'n_layers': 3, 'hidden_dim_0': 18, 'hidden_dim_1': 86, 'hidden_dim_2': 102, 'dropout_rate': 0.03018051223092133, 'learning_rate': 0.000822968416867227, 'weight_decay': 7.703690373629269e-06, 'use_layer_norm': True}. Best is trial 0 with value: 29.293935775756836.\n\uD83D\uDCA1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name    | Type         | Params | Mode \n-------------------------------------------------\n0 | model   | RegressionNN | 22.5 K | train\n1 | loss_fn | MSELoss      | 0      | train\n-------------------------------------------------\n22.5 K    Trainable params\n0         Non-trainable params\n22.5 K    Total params\n0.090     Total estimated model params size (MB)\n13        Modules in train mode\n0         Modules in eval mode\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/optuna/trial/_trial.py:501: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n  warnings.warn(\n`Trainer.fit` stopped: `max_epochs=50` reached.\n[I 2025-09-24 17:24:55,615] Trial 2 finished with value: 43.91607666015625 and parameters: {'n_layers': 3, 'hidden_dim_0': 121, 'hidden_dim_1': 119, 'hidden_dim_2': 52, 'dropout_rate': 0.44608633924135244, 'learning_rate': 0.00019565488462423714, 'weight_decay': 7.947601916738136e-05, 'use_layer_norm': False}. Best is trial 0 with value: 29.293935775756836.\n\uD83D\uDCA1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name    | Type         | Params | Mode \n-------------------------------------------------\n0 | model   | RegressionNN | 16.4 K | train\n1 | loss_fn | MSELoss      | 0      | train\n-------------------------------------------------\n16.4 K    Trainable params\n0         Non-trainable params\n16.4 K    Total params\n0.066     Total estimated model params size (MB)\n16        Modules in train mode\n0         Modules in eval mode\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/optuna/trial/_trial.py:501: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n  warnings.warn(\n[I 2025-09-24 17:25:20,010] Trial 3 finished with value: 38.551788330078125 and parameters: {'n_layers': 3, 'hidden_dim_0': 57, 'hidden_dim_1': 104, 'hidden_dim_2': 86, 'dropout_rate': 0.4950391075701487, 'learning_rate': 0.004421663119733494, 'weight_decay': 1.3290370643913522e-06, 'use_layer_norm': True}. Best is trial 0 with value: 29.293935775756836.\n\uD83D\uDCA1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name    | Type         | Params | Mode \n-------------------------------------------------\n0 | model   | RegressionNN | 19.6 K | train\n1 | loss_fn | MSELoss      | 0      | train\n-------------------------------------------------\n19.6 K    Trainable params\n0         Non-trainable params\n19.6 K    Total params\n0.079     Total estimated model params size (MB)\n16        Modules in train mode\n0         Modules in eval mode\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/optuna/trial/_trial.py:501: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n  warnings.warn(\n`Trainer.fit` stopped: `max_epochs=50` reached.\n[I 2025-09-24 17:26:03,672] Trial 4 finished with value: 36.3152961730957 and parameters: {'n_layers': 3, 'hidden_dim_0': 94, 'hidden_dim_1': 83, 'hidden_dim_2': 116, 'dropout_rate': 0.4827217053567506, 'learning_rate': 0.0007888868805889999, 'weight_decay': 6.936577802044803e-05, 'use_layer_norm': True}. Best is trial 0 with value: 29.293935775756836.\n\uD83D\uDCA1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name    | Type         | Params | Mode \n-------------------------------------------------\n0 | model   | RegressionNN | 664    | train\n1 | loss_fn | MSELoss      | 0      | train\n-------------------------------------------------\n664       Trainable params\n0         Non-trainable params\n664       Total params\n0.003     Total estimated model params size (MB)\n8         Modules in train mode\n0         Modules in eval mode\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/optuna/trial/_trial.py:501: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n  warnings.warn(\n[I 2025-09-24 17:26:05,407] Trial 5 pruned. Trial was pruned at epoch 1.\n\uD83D\uDCA1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name    | Type         | Params | Mode \n-------------------------------------------------\n0 | model   | RegressionNN | 9.7 K  | train\n1 | loss_fn | MSELoss      | 0      | train\n-------------------------------------------------\n9.7 K     Trainable params\n0         Non-trainable params\n9.7 K     Total params\n0.039     Total estimated model params size (MB)\n10        Modules in train mode\n0         Modules in eval mode\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/optuna/trial/_trial.py:501: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n  warnings.warn(\n[I 2025-09-24 17:26:20,814] Trial 6 finished with value: 30.9840145111084 and parameters: {'n_layers': 2, 'hidden_dim_0': 102, 'hidden_dim_1': 80, 'dropout_rate': 0.3320754419102381, 'learning_rate': 0.0016479039099819696, 'weight_decay': 2.4238851621734587e-06, 'use_layer_norm': False}. Best is trial 0 with value: 29.293935775756836.\n\uD83D\uDCA1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name    | Type         | Params | Mode \n-------------------------------------------------\n0 | model   | RegressionNN | 11.6 K | train\n1 | loss_fn | MSELoss      | 0      | train\n-------------------------------------------------\n11.6 K    Trainable params\n0         Non-trainable params\n11.6 K    Total params\n0.046     Total estimated model params size (MB)\n16        Modules in train mode\n0         Modules in eval mode\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n[I 2025-09-24 17:26:21,522] Trial 7 pruned. Trial was pruned at epoch 0.\n\uD83D\uDCA1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name    | Type         | Params | Mode \n-------------------------------------------------\n0 | model   | RegressionNN | 736    | train\n1 | loss_fn | MSELoss      | 0      | train\n-------------------------------------------------\n736       Trainable params\n0         Non-trainable params\n736       Total params\n0.003     Total estimated model params size (MB)\n7         Modules in train mode\n0         Modules in eval mode\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n[I 2025-09-24 17:26:22,122] Trial 8 pruned. Trial was pruned at epoch 0.\n\uD83D\uDCA1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name    | Type         | Params | Mode \n-------------------------------------------------\n0 | model   | RegressionNN | 1.8 K  | train\n1 | loss_fn | MSELoss      | 0      | train\n-------------------------------------------------\n1.8 K     Trainable params\n0         Non-trainable params\n1.8 K     Total params\n0.007     Total estimated model params size (MB)\n7         Modules in train mode\n0         Modules in eval mode\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n[I 2025-09-24 17:26:22,819] Trial 9 pruned. Trial was pruned at epoch 0.\n\uD83D\uDCA1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name    | Type         | Params | Mode \n-------------------------------------------------\n0 | model   | RegressionNN | 3.1 K  | train\n1 | loss_fn | MSELoss      | 0      | train\n-------------------------------------------------\n3.1 K     Trainable params\n0         Non-trainable params\n3.1 K     Total params\n0.012     Total estimated model params size (MB)\n12        Modules in train mode\n0         Modules in eval mode\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n[I 2025-09-24 17:26:23,494] Trial 10 pruned. Trial was pruned at epoch 0.\n\uD83D\uDCA1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name    | Type         | Params | Mode \n-------------------------------------------------\n0 | model   | RegressionNN | 7.3 K  | train\n1 | loss_fn | MSELoss      | 0      | train\n-------------------------------------------------\n7.3 K     Trainable params\n0         Non-trainable params\n7.3 K     Total params\n0.029     Total estimated model params size (MB)\n10        Modules in train mode\n0         Modules in eval mode\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n[I 2025-09-24 17:26:24,111] Trial 11 pruned. Trial was pruned at epoch 0.\n\uD83D\uDCA1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name    | Type         | Params | Mode \n-------------------------------------------------\n0 | model   | RegressionNN | 8.5 K  | train\n1 | loss_fn | MSELoss      | 0      | train\n-------------------------------------------------\n8.5 K     Trainable params\n0         Non-trainable params\n8.5 K     Total params\n0.034     Total estimated model params size (MB)\n10        Modules in train mode\n0         Modules in eval mode\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n[I 2025-09-24 17:26:24,838] Trial 12 pruned. Trial was pruned at epoch 0.\n\uD83D\uDCA1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name    | Type         | Params | Mode \n-------------------------------------------------\n0 | model   | RegressionNN | 11.7 K | train\n1 | loss_fn | MSELoss      | 0      | train\n-------------------------------------------------\n11.7 K    Trainable params\n0         Non-trainable params\n11.7 K    Total params\n0.047     Total estimated model params size (MB)\n10        Modules in train mode\n0         Modules in eval mode\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/optuna/trial/_trial.py:501: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n  warnings.warn(\n[I 2025-09-24 17:26:29,210] Trial 13 pruned. Trial was pruned at epoch 3.\n\uD83D\uDCA1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name    | Type         | Params | Mode \n-------------------------------------------------\n0 | model   | RegressionNN | 4.6 K  | train\n1 | loss_fn | MSELoss      | 0      | train\n-------------------------------------------------\n4.6 K     Trainable params\n0         Non-trainable params\n4.6 K     Total params\n0.018     Total estimated model params size (MB)\n12        Modules in train mode\n0         Modules in eval mode\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/optuna/trial/_trial.py:501: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n  warnings.warn(\n[I 2025-09-24 17:26:49,681] Trial 14 finished with value: 32.5185661315918 and parameters: {'n_layers': 2, 'hidden_dim_0': 82, 'hidden_dim_1': 38, 'dropout_rate': 0.24712188586191056, 'learning_rate': 0.009959603942172284, 'weight_decay': 2.8470288891470384e-05, 'use_layer_norm': True}. Best is trial 0 with value: 29.293935775756836.\n\uD83D\uDCA1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name    | Type         | Params | Mode \n-------------------------------------------------\n0 | model   | RegressionNN | 10.1 K | train\n1 | loss_fn | MSELoss      | 0      | train\n-------------------------------------------------\n10.1 K    Trainable params\n0         Non-trainable params\n10.1 K    Total params\n0.040     Total estimated model params size (MB)\n10        Modules in train mode\n0         Modules in eval mode\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/optuna/trial/_trial.py:501: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n  warnings.warn(\n[I 2025-09-24 17:27:14,684] Trial 15 finished with value: 28.95313835144043 and parameters: {'n_layers': 2, 'hidden_dim_0': 110, 'hidden_dim_1': 76, 'dropout_rate': 0.3698762377583922, 'learning_rate': 0.0036535876956035706, 'weight_decay': 0.0007561450165480699, 'use_layer_norm': False}. Best is trial 15 with value: 28.95313835144043.\n\uD83D\uDCA1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name    | Type         | Params | Mode \n-------------------------------------------------\n0 | model   | RegressionNN | 1.7 K  | train\n1 | loss_fn | MSELoss      | 0      | train\n-------------------------------------------------\n1.7 K     Trainable params\n0         Non-trainable params\n1.7 K     Total params\n0.007     Total estimated model params size (MB)\n7         Modules in train mode\n0         Modules in eval mode\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/optuna/trial/_trial.py:501: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n  warnings.warn(\n[I 2025-09-24 17:27:16,375] Trial 16 pruned. Trial was pruned at epoch 1.\n\uD83D\uDCA1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name    | Type         | Params | Mode \n-------------------------------------------------\n0 | model   | RegressionNN | 13.1 K | train\n1 | loss_fn | MSELoss      | 0      | train\n-------------------------------------------------\n13.1 K    Trainable params\n0         Non-trainable params\n13.1 K    Total params\n0.052     Total estimated model params size (MB)\n12        Modules in train mode\n0         Modules in eval mode\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n[I 2025-09-24 17:27:16,998] Trial 17 pruned. Trial was pruned at epoch 0.\n\uD83D\uDCA1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name    | Type         | Params | Mode \n-------------------------------------------------\n0 | model   | RegressionNN | 14.9 K | train\n1 | loss_fn | MSELoss      | 0      | train\n-------------------------------------------------\n14.9 K    Trainable params\n0         Non-trainable params\n14.9 K    Total params\n0.060     Total estimated model params size (MB)\n10        Modules in train mode\n0         Modules in eval mode\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n[I 2025-09-24 17:27:17,659] Trial 18 pruned. Trial was pruned at epoch 0.\n\uD83D\uDCA1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name    | Type         | Params | Mode \n-------------------------------------------------\n0 | model   | RegressionNN | 1.2 K  | train\n1 | loss_fn | MSELoss      | 0      | train\n-------------------------------------------------\n1.2 K     Trainable params\n0         Non-trainable params\n1.2 K     Total params\n0.005     Total estimated model params size (MB)\n8         Modules in train mode\n0         Modules in eval mode\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/optuna/trial/_trial.py:501: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n  warnings.warn(\n[I 2025-09-24 17:27:42,342] Trial 19 finished with value: 28.82682228088379 and parameters: {'n_layers': 1, 'hidden_dim_0': 71, 'dropout_rate': 0.09295014938940827, 'learning_rate': 0.006342731825213631, 'weight_decay': 6.949821071041785e-05, 'use_layer_norm': True}. Best is trial 19 with value: 28.82682228088379.\n\uD83D\uDCA1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1faf218163f45a4ab0e66305afda6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    37.515480041503906     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mae          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     4.822134017944336     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_rmse         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     6.072261333465576     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1m       Test metric       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      DataLoader 0       \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001B[36m \u001B[0m\u001B[36m        test_loss        \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m   37.515480041503906    \u001B[0m\u001B[35m \u001B[0m│\n",
       "│\u001B[36m \u001B[0m\u001B[36m        test_mae         \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m    4.822134017944336    \u001B[0m\u001B[35m \u001B[0m│\n",
       "│\u001B[36m \u001B[0m\u001B[36m        test_rmse        \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m    6.072261333465576    \u001B[0m\u001B[35m \u001B[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n2025/09/24 17:27:42 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n\uD83D\uDD17 View Logged Model at: https://e2-demo-field-eng.cloud.databricks.com/ml/experiments/2964497923484677/models/m-57fc0bf92d054d22a4327d4d2ccec1d7?o=1444828305810485\nRegistered model 'baraldi_catalog.regression.pytorch_regression_optimized' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47879a25c2e4059b25d593dd667e75e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD17 Created version '3' of model 'baraldi_catalog.regression.pytorch_regression_optimized': https://e2-demo-field-eng.cloud.databricks.com/explore/data/models/baraldi_catalog/regression/pytorch_regression_optimized/version/3?o=1444828305810485\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model logged: models:/m-57fc0bf92d054d22a4327d4d2ccec1d7\nBest parameters: {'n_layers': 1, 'hidden_dim_0': 71, 'dropout_rate': 0.09295014938940827, 'learning_rate': 0.006342731825213631, 'weight_decay': 6.949821071041785e-05, 'use_layer_norm': True}\nTest RMSE: 6.1250\nTest MAE: 4.8221\nTest R²: 0.8517\n"
     ]
    }
   ],
   "source": [
    "# Crie um callback como fallback\n",
    "class PyTorchLightningPruningCallback(pl.Callback):\n",
    "    \"\"\"PyTorch Lightning callback to prune unpromising trials.\n",
    "    \n",
    "    This is a simplified version for use when the optuna-integration package isn't available.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, trial, monitor):\n",
    "        super().__init__()\n",
    "        self._trial = trial\n",
    "        self.monitor = monitor\n",
    "        \n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        # Reporte a métrica de validação ao Optuna\n",
    "        metrics = trainer.callback_metrics\n",
    "        current_score = metrics.get(self.monitor)\n",
    "        \n",
    "        if current_score is not None:\n",
    "            self._trial.report(current_score.item(), trainer.current_epoch)\n",
    "            \n",
    "            if self._trial.should_prune():\n",
    "                message = \"Trial was pruned at epoch {}.\".format(trainer.current_epoch)\n",
    "                raise optuna.TrialPruned(message)\n",
    "\n",
    "# Gere um dataset maior para tuning de hiperparâmetros\n",
    "n_samples = 2000\n",
    "n_features = 10\n",
    "\n",
    "X, y = create_regression_data(n_samples=n_samples, n_features=n_features, nonlinear=True)\n",
    "\n",
    "# Divida os dados\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Prepare a avaliação\n",
    "evaluation_data = X_test.copy()\n",
    "evaluation_data[\"label\"] = y_test\n",
    "\n",
    "# Crie os data loaders\n",
    "batch_size = 32\n",
    "train_loader, val_loader, test_loader, scaler = prepare_dataloader(\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Optuna objective function to minimize validation loss.\"\"\"\n",
    "    \n",
    "    # Defina o espaço de busca\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    \n",
    "    # Crie as dimensões escondidas baseadp no número de camadas\n",
    "    hidden_dims = []\n",
    "    for i in range(n_layers):\n",
    "        hidden_dims.append(trial.suggest_int(f\"hidden_dim_{i}\", 16, 128))\n",
    "    \n",
    "    # Outros hiperparâmetros\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.0, 0.5)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "    use_layer_norm = trial.suggest_categorical(\"use_layer_norm\", [True, False])\n",
    "    \n",
    "    # Inicie uma execução nested do MLflow\n",
    "    with mlflow.start_run(nested=True) as child_run:\n",
    "        # Crie o client do MLflow para registro batch\n",
    "        mlflow_client = MlflowClient()\n",
    "        run_id = child_run.info.run_id\n",
    "        \n",
    "        # Prepare os parãmetros para registro batch\n",
    "        params_list = []\n",
    "        param_dict = {\n",
    "            \"n_layers\": n_layers,\n",
    "            \"hidden_dims\": str(hidden_dims),\n",
    "            \"dropout_rate\": dropout_rate,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"use_layer_norm\": use_layer_norm,\n",
    "            \"batch_size\": batch_size\n",
    "        }\n",
    "        \n",
    "        # Converta parametros para Param objects\n",
    "        for key, value in param_dict.items():\n",
    "            params_list.append(Param(key, str(value)))\n",
    "        \n",
    "        # Crie o modelo com esses hiperparametros\n",
    "        model = RegressionLightningModule(\n",
    "            input_dim=X_train.shape[1],\n",
    "            hidden_dims=hidden_dims,\n",
    "            dropout_rate=dropout_rate,\n",
    "            use_layer_norm=use_layer_norm,\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "        \n",
    "        # Callbacks\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            mode='min'\n",
    "        )\n",
    "        \n",
    "        pruning_callback = PyTorchLightningPruningCallback(\n",
    "            trial, monitor=\"val_loss\"\n",
    "        )\n",
    "        \n",
    "        # Defina o trainer\n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=50,\n",
    "            callbacks=[early_stopping, pruning_callback],\n",
    "            enable_progress_bar=False,\n",
    "            log_every_n_steps=10\n",
    "        )\n",
    "        \n",
    "        # Treine e valide o modelo\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "        \n",
    "        # Selecione o melhor na validação\n",
    "        best_val_loss = trainer.callback_metrics.get(\"val_loss\").item()\n",
    "        val_rmse = np.sqrt(best_val_loss)\n",
    "        \n",
    "        # Prepare métricas para registro batch\n",
    "        current_time = int(time.time() * 1000)\n",
    "        metrics_list = [\n",
    "            Metric(\"val_loss\", best_val_loss, current_time, 0),\n",
    "            Metric(\"val_rmse\", val_rmse, current_time, 0)\n",
    "        ]\n",
    "        \n",
    "        # Use log_batch\n",
    "        mlflow_client.log_batch(run_id, metrics=metrics_list, params=params_list)\n",
    "        \n",
    "    # Armazene o modelo com user attributes\n",
    "    trial.set_user_attr(\"model\", model)\n",
    "    \n",
    "    # Retorne o valor para minimizar\n",
    "    return best_val_loss\n",
    "\n",
    "best_model_version = None\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow_client = MlflowClient()\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=20)\n",
    "\n",
    "    best_trial = study.best_trial\n",
    "    best_model = best_trial.user_attrs[\"model\"]\n",
    "    \n",
    "    # Teste o melhor modelo\n",
    "    trainer = pl.Trainer(\n",
    "        enable_progress_bar=True,\n",
    "        log_every_n_steps=5\n",
    "    )\n",
    "    test_results = trainer.test(best_model, test_loader)\n",
    "    \n",
    "    # Faça predições no teste\n",
    "    best_model.eval()\n",
    "    test_preds = []\n",
    "    true_values = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            x, y = batch\n",
    "            y_pred = best_model(x)\n",
    "            test_preds.extend(y_pred.numpy())\n",
    "            true_values.extend(y.numpy())\n",
    "    \n",
    "    test_preds = np.array(test_preds)\n",
    "    true_values = np.array(true_values)\n",
    "    \n",
    "    # Calcule métricas\n",
    "    rmse = np.sqrt(mean_squared_error(true_values, test_preds))\n",
    "    mae = mean_absolute_error(true_values, test_preds)\n",
    "    r2 = r2_score(true_values, test_preds)\n",
    "    \n",
    "    # Prepare parâmetros para registro\n",
    "    best_params_list = []\n",
    "    for key, value in best_trial.params.items():\n",
    "        best_params_list.append(Param(f\"best_{key}\", str(value)))\n",
    "    \n",
    "    # Prepare métricas\n",
    "    current_time = int(time.time() * 1000)\n",
    "    metrics_list = [\n",
    "        Metric(\"best_val_loss\", best_trial.value, current_time, 0),\n",
    "        Metric(\"test_rmse\", rmse, current_time, 0),\n",
    "        Metric(\"test_mae\", mae, current_time, 0),\n",
    "        Metric(\"test_r2\", r2, current_time, 0)\n",
    "    ]\n",
    "    \n",
    "    # Registre métricas e parâmetros\n",
    "    mlflow_client.log_batch(run_id, metrics=metrics_list, params=best_params_list)\n",
    "\n",
    "    # Gere a assinatura do modelo\n",
    "    input_example = X_train.iloc[[0]].values.astype(np.float32)\n",
    "    input_example_scaled = scaler.transform(input_example).astype(np.float32)\n",
    "    \n",
    "    best_model.eval()\n",
    "    with torch.no_grad():\n",
    "        tensor_input = torch.tensor(input_example_scaled, dtype=torch.float32)\n",
    "        signature_preds = best_model(tensor_input)\n",
    "    \n",
    "    signature = infer_signature(input_example, signature_preds.numpy().reshape(-1).astype(np.float32))\n",
    "\n",
    "    # Registre o modelo\n",
    "    model_info = mlflow.pytorch.log_model(\n",
    "        best_model,\n",
    "        artifact_path=\"model\",\n",
    "        input_example=input_example,\n",
    "        signature=signature,\n",
    "        registered_model_name=\"baraldi_catalog.regression.pytorch_regression_optimized\",\n",
    "    )\n",
    "    \n",
    "    # Crie o gráfico residual\n",
    "    residual_plot = plot_residuals(pd.Series(true_values), test_preds)\n",
    "    \n",
    "    # Registre as figuras\n",
    "    mlflow.log_figure(dist_plot, \"feature_distributions.png\")\n",
    "    mlflow.log_figure(corr_plot, \"correlation_heatmap.png\")\n",
    "    mlflow.log_figure(scatter_plot, \"feature_target_relationships.png\")\n",
    "    mlflow.log_figure(pairwise_plot, \"pairwise_relationships.png\")\n",
    "    mlflow.log_figure(outlier_plot, \"outlier_detection.png\")\n",
    "    mlflow.log_figure(residual_plot, \"residual_plot.png\")\n",
    "\n",
    "    # Pule o MLflow para evitar erros\n",
    "    print(f\"Best model logged: {model_info.model_uri}\")\n",
    "    print(f\"Best parameters: {best_trial.params}\")\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n",
    "    print(f\"Test MAE: {mae:.4f}\")\n",
    "    print(f\"Test R²: {r2:.4f}\")\n",
    "\n",
    "    best_model_version = model_info.registered_model_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7556300-f197-41f8-9c77-d553e492d180",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "# Inicialize o client do MLflow\n",
    "client = MlflowClient()\n",
    "\n",
    "# Configure um alias para a melhor versão\n",
    "# This makes it easier to reference specific model versions programmatically\n",
    "client.set_registered_model_alias(\"baraldi_catalog.regression.pytorch_regression_optimized\", \"best\", int(best_model_version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5aafba8-7f07-4866-ad28-9b7509a19e1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8908e8d0fc84575b0686f5604c7cefe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/24 17:28:01 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5858d9b8cc1e4fc3b9f7666d197946a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/24 17:28:02 INFO mlflow.utils.virtualenv: Creating a new environment in /tmp/virtualenv_envs/mlflow-062a26c0832d863b3ba4dd142d5ea52c63c5e637 with python version 3.10.12 using uv\nUsing CPython 3.10.12 interpreter at: \u001B[36m/usr/bin/python3.10\u001B[39m\nCreating virtual environment at: \u001B[36m/tmp/virtualenv_envs/mlflow-062a26c0832d863b3ba4dd142d5ea52c63c5e637\u001B[39m\nActivate with: \u001B[32msource /tmp/virtualenv_envs/mlflow-062a26c0832d863b3ba4dd142d5ea52c63c5e637/bin/activate\u001B[39m\n2025/09/24 17:28:03 INFO mlflow.utils.virtualenv: Installing dependencies\n\u001B[2mUsing Python 3.10.12 environment at: /tmp/virtualenv_envs/mlflow-062a26c0832d863b3ba4dd142d5ea52c63c5e637\u001B[0m\n\u001B[2mResolved \u001B[1m3 packages\u001B[0m \u001B[2min 123ms\u001B[0m\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m pip \u001B[2m(2.0MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m setuptools \u001B[2m(1.2MiB)\u001B[0m\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m setuptools\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m pip\n\u001B[2mPrepared \u001B[1m3 packages\u001B[0m \u001B[2min 115ms\u001B[0m\u001B[0m\n\u001B[2mInstalled \u001B[1m3 packages\u001B[0m \u001B[2min 16ms\u001B[0m\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpip\u001B[0m\u001B[2m==22.3.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msetuptools\u001B[0m\u001B[2m==65.5.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mwheel\u001B[0m\u001B[2m==0.38.4\u001B[0m\n\u001B[2mUsing Python 3.10.12 environment at: /tmp/virtualenv_envs/mlflow-062a26c0832d863b3ba4dd142d5ea52c63c5e637\u001B[0m\n\u001B[2mResolved \u001B[1m167 packages\u001B[0m \u001B[2min 999ms\u001B[0m\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m aiohttp \u001B[2m(1.6MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m jedi \u001B[2m(1.5MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m pillow \u001B[2m(6.3MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m sympy \u001B[2m(6.0MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m nvidia-cusparse-cu12 \u001B[2m(274.9MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m scikit-learn \u001B[2m(9.2MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m sqlalchemy \u001B[2m(3.1MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m fonttools \u001B[2m(4.6MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m nvidia-nccl-cu12 \u001B[2m(307.4MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m nvidia-cudnn-cu12 \u001B[2m(674.0MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m nvidia-cusparselt-cu12 \u001B[2m(273.9MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m cryptography \u001B[2m(4.2MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m nvidia-cufile-cu12 \u001B[2m(1.1MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m pygments \u001B[2m(1.2MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m scipy \u001B[2m(32.8MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m nvidia-nvjitlink-cu12 \u001B[2m(37.4MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m mlflow \u001B[2m(25.5MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m pydantic-core \u001B[2m(1.9MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m mlflow-skinny \u001B[2m(2.1MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m mlflow-tracing \u001B[2m(1.2MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m pyarrow \u001B[2m(40.8MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m nvidia-cusolver-cu12 \u001B[2m(255.1MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m nvidia-cufft-cu12 \u001B[2m(184.2MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m nvidia-cuda-cupti-cu12 \u001B[2m(9.8MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m nvidia-curand-cu12 \u001B[2m(60.7MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m triton \u001B[2m(148.2MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m pandas \u001B[2m(11.5MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m kiwisolver \u001B[2m(1.6MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m torch \u001B[2m(846.9MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m numpy \u001B[2m(16.3MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m matplotlib \u001B[2m(11.0MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m nvidia-cuda-nvrtc-cu12 \u001B[2m(84.0MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m networkx \u001B[2m(1.6MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m nvidia-cublas-cu12 \u001B[2m(566.8MiB)\u001B[0m\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m nvidia-cufile-cu12\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m pygments\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m aiohttp\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m kiwisolver\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m pydantic-core\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m mlflow-tracing\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m networkx\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m sqlalchemy\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m mlflow-skinny\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m cryptography\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m fonttools\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m pillow\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m nvidia-cuda-cupti-cu12\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m sympy\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m matplotlib\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m scikit-learn\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m pandas\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m jedi\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m numpy\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m nvidia-nvjitlink-cu12\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m scipy\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m mlflow\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m nvidia-curand-cu12\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m pyarrow\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m nvidia-cuda-nvrtc-cu12\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m triton\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m nvidia-cufft-cu12\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m nvidia-cusolver-cu12\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m nvidia-cusparse-cu12\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m nvidia-cusparselt-cu12\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m nvidia-nccl-cu12\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m nvidia-cublas-cu12\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m nvidia-cudnn-cu12\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m torch\n\u001B[2mPrepared \u001B[1m165 packages\u001B[0m \u001B[2min 44.25s\u001B[0m\u001B[0m\n\u001B[2mInstalled \u001B[1m165 packages\u001B[0m \u001B[2min 804ms\u001B[0m\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1maiohappyeyeballs\u001B[0m\u001B[2m==2.6.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1maiohttp\u001B[0m\u001B[2m==3.12.15\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1maiosignal\u001B[0m\u001B[2m==1.4.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1malembic\u001B[0m\u001B[2m==1.16.5\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mannotated-types\u001B[0m\u001B[2m==0.7.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1manyio\u001B[0m\u001B[2m==4.11.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1masttokens\u001B[0m\u001B[2m==3.0.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mastunparse\u001B[0m\u001B[2m==1.6.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1masync-timeout\u001B[0m\u001B[2m==5.0.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mattrs\u001B[0m\u001B[2m==25.3.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mauthlib\u001B[0m\u001B[2m==1.6.4\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mbackcall\u001B[0m\u001B[2m==0.2.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mblinker\u001B[0m\u001B[2m==1.9.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcachetools\u001B[0m\u001B[2m==5.5.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcertifi\u001B[0m\u001B[2m==2025.8.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcffi\u001B[0m\u001B[2m==2.0.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcharset-normalizer\u001B[0m\u001B[2m==3.4.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mclick\u001B[0m\u001B[2m==8.3.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcloudpickle\u001B[0m\u001B[2m==3.1.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcontourpy\u001B[0m\u001B[2m==1.3.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcryptography\u001B[0m\u001B[2m==45.0.7\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcycler\u001B[0m\u001B[2m==0.12.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcyclopts\u001B[0m\u001B[2m==3.24.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdatabricks-sdk\u001B[0m\u001B[2m==0.66.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdecorator\u001B[0m\u001B[2m==5.2.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdefusedxml\u001B[0m\u001B[2m==0.7.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdnspython\u001B[0m\u001B[2m==2.8.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdocker\u001B[0m\u001B[2m==7.1.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdocstring-parser\u001B[0m\u001B[2m==0.17.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdocutils\u001B[0m\u001B[2m==0.22.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1memail-validator\u001B[0m\u001B[2m==2.3.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mexceptiongroup\u001B[0m\u001B[2m==1.3.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mexecuting\u001B[0m\u001B[2m==2.2.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mfastapi\u001B[0m\u001B[2m==0.117.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mfastmcp\u001B[0m\u001B[2m==2.12.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mfilelock\u001B[0m\u001B[2m==3.19.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mflask\u001B[0m\u001B[2m==3.1.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mfonttools\u001B[0m\u001B[2m==4.60.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mfrozenlist\u001B[0m\u001B[2m==1.7.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mfsspec\u001B[0m\u001B[2m==2025.9.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgitdb\u001B[0m\u001B[2m==4.0.12\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgitpython\u001B[0m\u001B[2m==3.1.45\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgoogle-auth\u001B[0m\u001B[2m==2.40.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgraphene\u001B[0m\u001B[2m==3.4.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgraphql-core\u001B[0m\u001B[2m==3.2.6\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgraphql-relay\u001B[0m\u001B[2m==3.2.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgreenlet\u001B[0m\u001B[2m==3.2.4\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgunicorn\u001B[0m\u001B[2m==23.0.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mh11\u001B[0m\u001B[2m==0.16.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mhttpcore\u001B[0m\u001B[2m==1.0.9\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mhttpx\u001B[0m\u001B[2m==0.28.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mhttpx-sse\u001B[0m\u001B[2m==0.4.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1midna\u001B[0m\u001B[2m==3.10\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mimportlib-metadata\u001B[0m\u001B[2m==8.7.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mipython\u001B[0m\u001B[2m==8.14.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1misodate\u001B[0m\u001B[2m==0.7.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mitsdangerous\u001B[0m\u001B[2m==2.2.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mjedi\u001B[0m\u001B[2m==0.19.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mjinja2\u001B[0m\u001B[2m==3.1.6\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mjoblib\u001B[0m\u001B[2m==1.5.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mjsonschema\u001B[0m\u001B[2m==4.25.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mjsonschema-path\u001B[0m\u001B[2m==0.3.4\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mjsonschema-specifications\u001B[0m\u001B[2m==2025.9.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mkiwisolver\u001B[0m\u001B[2m==1.4.9\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlazy-object-proxy\u001B[0m\u001B[2m==1.12.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlightning-utilities\u001B[0m\u001B[2m==0.15.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmako\u001B[0m\u001B[2m==1.3.10\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmarkdown-it-py\u001B[0m\u001B[2m==4.0.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmarkupsafe\u001B[0m\u001B[2m==3.0.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmatplotlib\u001B[0m\u001B[2m==3.7.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmatplotlib-inline\u001B[0m\u001B[2m==0.1.7\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmcp\u001B[0m\u001B[2m==1.14.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmdurl\u001B[0m\u001B[2m==0.1.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmlflow\u001B[0m\u001B[2m==3.4.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmlflow-skinny\u001B[0m\u001B[2m==3.4.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmlflow-tracing\u001B[0m\u001B[2m==3.4.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmore-itertools\u001B[0m\u001B[2m==10.8.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmpmath\u001B[0m\u001B[2m==1.3.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmultidict\u001B[0m\u001B[2m==6.6.4\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mnetworkx\u001B[0m\u001B[2m==3.4.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mnumpy\u001B[0m\u001B[2m==1.23.5\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mnvidia-cublas-cu12\u001B[0m\u001B[2m==12.8.4.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mnvidia-cuda-cupti-cu12\u001B[0m\u001B[2m==12.8.90\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mnvidia-cuda-nvrtc-cu12\u001B[0m\u001B[2m==12.8.93\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mnvidia-cuda-runtime-cu12\u001B[0m\u001B[2m==12.8.90\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mnvidia-cudnn-cu12\u001B[0m\u001B[2m==9.10.2.21\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mnvidia-cufft-cu12\u001B[0m\u001B[2m==11.3.3.83\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mnvidia-cufile-cu12\u001B[0m\u001B[2m==1.13.1.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mnvidia-curand-cu12\u001B[0m\u001B[2m==10.3.9.90\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mnvidia-cusolver-cu12\u001B[0m\u001B[2m==11.7.3.90\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mnvidia-cusparse-cu12\u001B[0m\u001B[2m==12.5.8.93\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mnvidia-cusparselt-cu12\u001B[0m\u001B[2m==0.7.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mnvidia-nccl-cu12\u001B[0m\u001B[2m==2.27.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mnvidia-nvjitlink-cu12\u001B[0m\u001B[2m==12.8.93\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mnvidia-nvtx-cu12\u001B[0m\u001B[2m==12.8.90\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mopenapi-core\u001B[0m\u001B[2m==0.19.5\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mopenapi-pydantic\u001B[0m\u001B[2m==0.5.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mopenapi-schema-validator\u001B[0m\u001B[2m==0.6.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mopenapi-spec-validator\u001B[0m\u001B[2m==0.7.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mopentelemetry-api\u001B[0m\u001B[2m==1.37.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mopentelemetry-proto\u001B[0m\u001B[2m==1.37.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mopentelemetry-sdk\u001B[0m\u001B[2m==1.37.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mopentelemetry-semantic-conventions\u001B[0m\u001B[2m==0.58b0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpackaging\u001B[0m\u001B[2m==25.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpandas\u001B[0m\u001B[2m==1.5.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mparse\u001B[0m\u001B[2m==1.20.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mparso\u001B[0m\u001B[2m==0.8.5\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpathable\u001B[0m\u001B[2m==0.4.4\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpexpect\u001B[0m\u001B[2m==4.9.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpickleshare\u001B[0m\u001B[2m==0.7.5\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpillow\u001B[0m\u001B[2m==11.3.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mprompt-toolkit\u001B[0m\u001B[2m==3.0.52\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpropcache\u001B[0m\u001B[2m==0.3.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mprotobuf\u001B[0m\u001B[2m==6.32.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mptyprocess\u001B[0m\u001B[2m==0.7.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpure-eval\u001B[0m\u001B[2m==0.2.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpyarrow\u001B[0m\u001B[2m==21.0.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpyasn1\u001B[0m\u001B[2m==0.6.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpyasn1-modules\u001B[0m\u001B[2m==0.4.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpycparser\u001B[0m\u001B[2m==2.23\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpydantic\u001B[0m\u001B[2m==2.11.9\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpydantic-core\u001B[0m\u001B[2m==2.33.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpydantic-settings\u001B[0m\u001B[2m==2.11.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpygments\u001B[0m\u001B[2m==2.19.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpyparsing\u001B[0m\u001B[2m==3.2.5\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpyperclip\u001B[0m\u001B[2m==1.10.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpython-dateutil\u001B[0m\u001B[2m==2.9.0.post0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpython-dotenv\u001B[0m\u001B[2m==1.1.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpython-multipart\u001B[0m\u001B[2m==0.0.20\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpytorch-lightning\u001B[0m\u001B[2m==2.5.5\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpytz\u001B[0m\u001B[2m==2025.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpyyaml\u001B[0m\u001B[2m==6.0.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mreferencing\u001B[0m\u001B[2m==0.36.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mrequests\u001B[0m\u001B[2m==2.32.5\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mrfc3339-validator\u001B[0m\u001B[2m==0.1.4\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mrich\u001B[0m\u001B[2m==14.1.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mrich-rst\u001B[0m\u001B[2m==1.3.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mrpds-py\u001B[0m\u001B[2m==0.27.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mrsa\u001B[0m\u001B[2m==4.9.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mscikit-learn\u001B[0m\u001B[2m==1.7.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mscipy\u001B[0m\u001B[2m==1.10.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msix\u001B[0m\u001B[2m==1.17.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msmmap\u001B[0m\u001B[2m==5.0.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msniffio\u001B[0m\u001B[2m==1.3.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msqlalchemy\u001B[0m\u001B[2m==2.0.43\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msqlparse\u001B[0m\u001B[2m==0.5.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msse-starlette\u001B[0m\u001B[2m==3.0.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mstack-data\u001B[0m\u001B[2m==0.6.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mstarlette\u001B[0m\u001B[2m==0.48.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msympy\u001B[0m\u001B[2m==1.14.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mthreadpoolctl\u001B[0m\u001B[2m==3.6.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtomli\u001B[0m\u001B[2m==2.2.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtorch\u001B[0m\u001B[2m==2.8.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtorchmetrics\u001B[0m\u001B[2m==1.8.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtqdm\u001B[0m\u001B[2m==4.67.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtraitlets\u001B[0m\u001B[2m==5.14.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtriton\u001B[0m\u001B[2m==3.4.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtyping-extensions\u001B[0m\u001B[2m==4.15.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtyping-inspection\u001B[0m\u001B[2m==0.4.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1murllib3\u001B[0m\u001B[2m==2.5.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1muvicorn\u001B[0m\u001B[2m==0.37.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mwcwidth\u001B[0m\u001B[2m==0.2.14\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mwerkzeug\u001B[0m\u001B[2m==3.1.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1myarl\u001B[0m\u001B[2m==1.20.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mzipp\u001B[0m\u001B[2m==3.23.0\u001B[0m\n2025/09/24 17:28:50 INFO mlflow.utils.environment: === Running command '['bash', '-c', 'source /tmp/virtualenv_envs/mlflow-062a26c0832d863b3ba4dd142d5ea52c63c5e637/bin/activate && python -c \"\"']'\n2025/09/24 17:28:50 INFO mlflow.utils.environment: === Running command '['bash', '-c', 'source /tmp/virtualenv_envs/mlflow-062a26c0832d863b3ba4dd142d5ea52c63c5e637/bin/activate && python /local_disk0/.ephemeral_nfs/envs/pythonEnv-0ba82a78-e76e-45b6-b42e-e208ee580462/lib/python3.10/site-packages/mlflow/pyfunc/_mlflow_pyfunc_backend_predict.py --model-uri file:///local_disk0/user_tmp_data/spark-0ba82a78-e76e-45b6-b42e-e2/tmpbbc_k693 --content-type json --input-path /local_disk0/user_tmp_data/spark-0ba82a78-e76e-45b6-b42e-e2/tmpm_82qafq/input.json']'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [4.560913562774658, 68.66831970214844, 21.464685440063477, -2.942098617553711, -29.286977767944336, 0.31037479639053345, 60.218746185302734, 27.46315574645996, 2.072153329849243, -19.889680862426758, 11.099003791809082, -27.871129989624023, -1.8581024408340454, 2.1966629028320312, 18.643047332763672, 9.982495307922363, 13.43415641784668, -15.176512718200684, -7.65878438949585, -23.674821853637695, 61.83961868286133, -30.394691467285156, 34.45264434814453, -6.393752574920654, 11.448152542114258, -12.735569953918457, -3.6670424938201904, 43.3541259765625, -4.210549354553223, 28.95589828491211, 51.63481903076172, 38.606719970703125, 37.61429977416992, -18.438140869140625, 10.493430137634277, -29.15499496459961, 23.041114807128906, -18.788503646850586, 46.033809661865234, 17.189565658569336, -2.350978374481201, 42.12752914428711, -10.552478790283203, 30.31363296508789, 13.198495864868164, 5.433516502380371, 30.524444580078125, 20.052837371826172, -23.371023178100586, 1.6279749870300293, -19.48198699951172, 40.20014572143555, 8.405290603637695, -5.313895225524902, 33.975807189941406, 52.27897644042969, 34.85846710205078, -21.436830520629883, 27.701038360595703, 21.816852569580078, 66.62066650390625, 41.13178634643555, 27.598976135253906, -3.737703561782837, 0.4723660945892334, 27.644317626953125, 49.860260009765625, -2.090219020843506, 9.414324760437012, 56.364723205566406, -4.921597003936768, 36.70790100097656, 31.983489990234375, -11.363057136535645, 7.596706867218018, 44.97874069213867, -21.130475997924805, 19.294960021972656, -18.495027542114258, 24.975515365600586, -12.673983573913574, 35.881473541259766, 44.84325408935547, 5.4800190925598145, 5.413593292236328, -16.631927490234375, 6.681035995483398, -14.153437614440918, 47.05459213256836, -10.170228004455566, 46.77571105957031, 2.487100839614868, 17.719919204711914, 26.014474868774414, 2.7499587535858154, 2.346924066543579, -27.465551376342773, 57.983856201171875, -7.099554538726807, 29.4435977935791, -1.8184958696365356, -20.5100154876709, 19.07209014892578, 37.77815246582031, -5.501344203948975, -4.38115119934082, 11.098884582519531, -1.015467882156372, 30.77629852294922, -25.187437057495117, 54.56392288208008, -3.3835432529449463, 5.198493480682373, 32.60857391357422, 24.008827209472656, 7.482757568359375, 8.738932609558105, -21.66149139404297, 17.39612579345703, 42.04523849487305, 33.35520935058594, 28.787988662719727, 26.218137741088867, -21.610143661499023, 17.068477630615234, 56.19013595581055, 16.358848571777344, 19.982528686523438, 17.4503173828125, 14.72100830078125, 30.401611328125, 10.848967552185059, -0.4288083612918854, -4.802439212799072, -11.682156562805176, -6.3136820793151855, 55.785057067871094, 1.1885862350463867, 39.97722244262695, -10.601431846618652, 10.201701164245605, 31.888565063476562, 37.294532775878906, 57.89039993286133, 27.273324966430664, 4.668351650238037, 59.8689079284668, -12.027510643005371, -22.89812660217285, 25.444129943847656, 3.998922109603882, 30.880887985229492, 44.26367950439453, 20.632009506225586, 23.78321647644043, 33.351741790771484, 64.28461456298828, -17.95233154296875, 7.139277458190918, 67.9384765625, 7.999163627624512, 14.794832229614258, -15.28564453125, -19.741230010986328, 58.25100326538086, -14.484896659851074, 3.6291005611419678, 22.46949005126953, 36.33030319213867, 40.276912689208984, 38.320098876953125, -5.219363212585449, 31.67760467529297, 20.013622283935547, 0.3218978941440582, -27.11831283569336, 49.37953186035156, 6.2392802238464355, -0.6183981895446777, -1.782932162284851, 23.696836471557617, -13.62540340423584, -11.674591064453125, 24.438915252685547, 58.43692398071289, 30.269752502441406, 14.075485229492188, 41.934513092041016, -7.127303600311279, -18.173250198364258, -15.34372615814209, 16.77681541442871, 22.7511043548584, -7.8983564376831055, 14.874935150146484, -11.093316078186035, 36.17245864868164, 35.442806243896484, 36.81943893432617, -8.339018821716309, 13.10413932800293, -19.367252349853516, -2.7344279289245605, -9.835813522338867, 24.122848510742188, -24.373729705810547, 26.321836471557617, 64.13008880615234, 9.936636924743652, 10.493054389953613, -6.915073394775391, -11.8229341506958, 5.882962703704834, -17.421106338500977, 29.939010620117188, -13.469754219055176, -30.25527000427246, -10.023791313171387, 22.480632781982422, 57.899906158447266, 1.470130205154419, 7.8934760093688965, -20.664899826049805, 38.58338928222656, -32.16811752319336, 19.957889556884766, -0.05002525448799133, 52.08076858520508, -15.160510063171387, -29.81814193725586, 50.717464447021484, 31.465877532958984, 23.593963623046875, 42.10242462158203, 45.14857864379883, -4.668166637420654, -10.979883193969727, -4.3871026039123535, 12.297714233398438, -18.69672203063965, -21.729034423828125, 15.201342582702637, -8.16254711151123, 4.390121936798096, -13.086945533752441, -20.78753662109375, -22.16871452331543, -10.079339981079102, 9.830081939697266, 54.27698516845703, -3.041734218597412, 37.55563735961914, 21.056642532348633, 24.886655807495117, 5.561197280883789, 57.40724182128906, 41.5627555847168, -8.89221477508545, 13.071722030639648, 31.970420837402344, 32.5695686340332, 8.107783317565918, 51.97297286987305, 6.791513442993164, 25.530887603759766, -2.984682559967041, 5.418197154998779, -13.925628662109375, 8.18663215637207, 6.939972877502441, 21.053735733032227, -1.0423598289489746, 43.750980377197266, 47.81472396850586, -3.0581257343292236, 35.46204376220703, 33.194252014160156, -18.477584838867188, -3.5724189281463623, -12.610339164733887, -11.025004386901855, 40.31769561767578, -31.722970962524414, 1.9764809608459473, 31.734102249145508, 60.667015075683594, -16.500139236450195, 9.109530448913574, 11.092741012573242, 13.902487754821777, -12.167689323425293, 46.058692932128906, 47.992820739746094, 21.875120162963867, 7.303974628448486, 7.712436199188232, 36.83808135986328, -33.888671875, 44.266685485839844, 29.84720230102539]}"
     ]
    }
   ],
   "source": [
    "# Referencie o modelo pelo alias\n",
    "model_uri = \"models:/baraldi_catalog.regression.pytorch_regression_optimized@best\"\n",
    "\n",
    "# Valide se o modelo está deployado\n",
    "mlflow.models.predict(model_uri=model_uri, input_data=X_test, env_manager=\"uv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3dbe796-7c56-4438-abe3-b06c5dd1da69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5663c0a40e2a4f4fb019996c1ce5ea23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape das predições: (300,)\nPrimeiras 5 predições: [  4.5609136  68.66832    21.464685   -2.9420986 -29.286978 ]\nPrimeiros 5 valores reais: [  4.88613324  47.23380529  14.22780521 -11.25203095 -35.36736806]\n"
     ]
    }
   ],
   "source": [
    "# Converta os dados para float32\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Carregue o modelo usando a interface pyfunc\n",
    "loaded_model = mlflow.pyfunc.load_model(model_uri=model_uri)\n",
    "\n",
    "# Faça predições com o modelo\n",
    "predictions = loaded_model.predict(X_test)\n",
    "\n",
    "print(f\"Shape das predições: {predictions.shape}\")\n",
    "print(f\"Primeiras 5 predições: {predictions[:5]}\")\n",
    "print(f\"Primeiros 5 valores reais: {y_test.values[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "547a3124-a230-49c1-a3f7-71bbde5b9fd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffba906b14c44ddebbb5407ec65f077a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/24 17:29:20 WARNING mlflow.pyfunc: Calling `spark_udf()` with `env_manager=\"local\"` does not recreate the same environment that was used during training, which may lead to errors or inaccurate predictions. We recommend specifying `env_manager=\"conda\"`, which automatically recreates the environment that was used to train the model and performs inference in the recreated environment.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76f32bed4474e3ea002a41f9aa27f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/24 17:29:20 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>feature_0</th><th>feature_1</th><th>feature_2</th><th>feature_3</th><th>feature_4</th><th>feature_5</th><th>feature_6</th><th>feature_7</th><th>feature_8</th><th>feature_9</th><th>feature_correlated</th><th>feature_cyclical</th><th>feature_with_outliers</th><th>features_array</th><th>prediction</th></tr></thead><tbody><tr><td>0.7972175</td><td>-1.7150403</td><td>-0.383587</td><td>1.1108135</td><td>-1.1922657</td><td>-2.426833</td><td>1.6496313</td><td>-2.6474361</td><td>3.225119</td><td>2.1215987</td><td>0.53807855</td><td>-0.9909859</td><td>0.027851623</td><td>List(0.7972175, -1.7150403, -0.383587, 1.1108135, -1.1922657, -2.426833, 1.6496313, -2.6474361, 3.225119, 2.1215987, 0.53807855, -0.9909859, 0.027851623)</td><td>List(4.5609136)</td></tr><tr><td>4.467177</td><td>-4.731319</td><td>-4.3519573</td><td>-3.2893207</td><td>-2.328453</td><td>4.3216467</td><td>-1.8794254</td><td>4.6037183</td><td>1.223765</td><td>-1.1317749</td><td>3.729179</td><td>-0.97028726</td><td>-0.5052138</td><td>List(4.467177, -4.731319, -4.3519573, -3.2893207, -2.328453, 4.3216467, -1.8794254, 4.6037183, 1.223765, -1.1317749, 3.729179, -0.97028726, -0.5052138)</td><td>List(68.66832)</td></tr><tr><td>-3.3402305</td><td>-0.55784345</td><td>-2.9934723</td><td>0.02449961</td><td>-3.8878224</td><td>4.8379717</td><td>-4.2266774</td><td>-2.5728123</td><td>-2.286605</td><td>-0.3515369</td><td>-2.5367458</td><td>0.62058926</td><td>0.39984718</td><td>List(-3.3402305, -0.55784345, -2.9934723, 0.02449961, -3.8878224, 4.8379717, -4.2266774, -2.5728123, -2.286605, -0.3515369, -2.5367458, 0.62058926, 0.39984718)</td><td>List(21.464685)</td></tr><tr><td>2.7361856</td><td>-0.72013474</td><td>4.019054</td><td>-2.2003388</td><td>-4.8401675</td><td>4.219471</td><td>-0.17828454</td><td>3.6004436</td><td>4.0995502</td><td>0.4238995</td><td>2.2600062</td><td>-0.97252566</td><td>0.39559528</td><td>List(2.7361856, -0.72013474, 4.019054, -2.2003388, -4.8401675, 4.219471, -0.17828454, 3.6004436, 4.0995502, 0.4238995, 2.2600062, -0.97252566, 0.39559528)</td><td>List(-2.9420986)</td></tr><tr><td>-4.0238957</td><td>-4.995931</td><td>4.066411</td><td>-0.64817244</td><td>-4.279194</td><td>-2.181568</td><td>-2.3677466</td><td>-0.06761297</td><td>0.92267203</td><td>3.686881</td><td>-3.2872674</td><td>-0.97537553</td><td>0.10561319</td><td>List(-4.0238957, -4.995931, 4.066411, -0.64817244, -4.279194, -2.181568, -2.3677466, -0.06761297, 0.92267203, 3.686881, -3.2872674, -0.97537553, 0.10561319)</td><td>List(-29.28698)</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0.7972175,
         -1.7150403,
         -0.383587,
         1.1108135,
         -1.1922657,
         -2.426833,
         1.6496313,
         -2.6474361,
         3.225119,
         2.1215987,
         0.53807855,
         -0.9909859,
         0.027851623,
         [
          0.7972175,
          -1.7150403,
          -0.383587,
          1.1108135,
          -1.1922657,
          -2.426833,
          1.6496313,
          -2.6474361,
          3.225119,
          2.1215987,
          0.53807855,
          -0.9909859,
          0.027851623
         ],
         [
          4.5609136
         ]
        ],
        [
         4.467177,
         -4.731319,
         -4.3519573,
         -3.2893207,
         -2.328453,
         4.3216467,
         -1.8794254,
         4.6037183,
         1.223765,
         -1.1317749,
         3.729179,
         -0.97028726,
         -0.5052138,
         [
          4.467177,
          -4.731319,
          -4.3519573,
          -3.2893207,
          -2.328453,
          4.3216467,
          -1.8794254,
          4.6037183,
          1.223765,
          -1.1317749,
          3.729179,
          -0.97028726,
          -0.5052138
         ],
         [
          68.66832
         ]
        ],
        [
         -3.3402305,
         -0.55784345,
         -2.9934723,
         0.02449961,
         -3.8878224,
         4.8379717,
         -4.2266774,
         -2.5728123,
         -2.286605,
         -0.3515369,
         -2.5367458,
         0.62058926,
         0.39984718,
         [
          -3.3402305,
          -0.55784345,
          -2.9934723,
          0.02449961,
          -3.8878224,
          4.8379717,
          -4.2266774,
          -2.5728123,
          -2.286605,
          -0.3515369,
          -2.5367458,
          0.62058926,
          0.39984718
         ],
         [
          21.464685
         ]
        ],
        [
         2.7361856,
         -0.72013474,
         4.019054,
         -2.2003388,
         -4.8401675,
         4.219471,
         -0.17828454,
         3.6004436,
         4.0995502,
         0.4238995,
         2.2600062,
         -0.97252566,
         0.39559528,
         [
          2.7361856,
          -0.72013474,
          4.019054,
          -2.2003388,
          -4.8401675,
          4.219471,
          -0.17828454,
          3.6004436,
          4.0995502,
          0.4238995,
          2.2600062,
          -0.97252566,
          0.39559528
         ],
         [
          -2.9420986
         ]
        ],
        [
         -4.0238957,
         -4.995931,
         4.066411,
         -0.64817244,
         -4.279194,
         -2.181568,
         -2.3677466,
         -0.06761297,
         0.92267203,
         3.686881,
         -3.2872674,
         -0.97537553,
         0.10561319,
         [
          -4.0238957,
          -4.995931,
          4.066411,
          -0.64817244,
          -4.279194,
          -2.181568,
          -2.3677466,
          -0.06761297,
          0.92267203,
          3.686881,
          -3.2872674,
          -0.97537553,
          0.10561319
         ],
         [
          -29.28698
         ]
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "feature_0",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "feature_1",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "feature_2",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "feature_3",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "feature_4",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "feature_5",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "feature_6",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "feature_7",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "feature_8",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "feature_9",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "feature_correlated",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "feature_cyclical",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "feature_with_outliers",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "features_array",
         "type": "{\"containsNull\":true,\"elementType\":\"float\",\"type\":\"array\"}"
        },
        {
         "metadata": "{}",
         "name": "prediction",
         "type": "{\"containsNull\":true,\"elementType\":\"float\",\"type\":\"array\"}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import array, col\n",
    "\n",
    "# Converta o teste para um Spark DataFrame\n",
    "X_spark = spark.createDataFrame(X_test)\n",
    "\n",
    "# Crie uma array de todas as features\n",
    "# This step is necessary because:\n",
    "# 1. The PyTorch model expects an input tensor with shape [-1, 13]\n",
    "# 2. The model_udf needs to receive each row as a single array of 13 values\n",
    "# 3. Without this array transformation, 13 separate columns would be passed to the model\n",
    "#    which wouldn't match the expected tensor structure\n",
    "X_spark_with_array = X_spark.withColumn(\n",
    "    \"features_array\", \n",
    "    array(*[col(c) for c in X_spark.columns])\n",
    ")\n",
    "\n",
    "# Crie um Spark UDF do modelo registrado\n",
    "model_udf = mlflow.pyfunc.spark_udf(spark, model_uri=model_uri)\n",
    "\n",
    "# Aplique o MLflow UDF na array\n",
    "X_spark_with_predictions = X_spark_with_array.withColumn(\n",
    "    \"prediction\", \n",
    "    model_udf(\"features_array\")\n",
    ")\n",
    "\n",
    "display(X_spark_with_predictions.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c1f5e6b-346c-4d6e-8f27-f2159b415354",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "02_ML_Regression",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}